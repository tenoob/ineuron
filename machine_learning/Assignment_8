1. What exactly is a feature? Give an example to illustrate your point.
Ans. a feature is a column in the dataset. For example, in the titanic dataset, the passenger survived or not column is a feature.

2. What are the various circumstances in which feature construction is required?
Ans. feature construction is required when we want a new feature that can be created using an existing feature or by combining 2 or more features.

3. Describe how nominal variables are encoded.
Ans. nominal variables are encoded using one-hot encoding where All the variables in the respective feature are equal. We can't give them any orders or ranks.

4. Describe how numeric features are converted to categorical features.
Ans numerical features can be converted into categorical features using binning like for a students marks bins can be created for certain range of marks like >90 then A , 75-90 then B so on.

5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this
approach?
Ans.  It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion wrapper classification algorithms with joint dimensionality reduction and classification can also be used but these methods have high computation cost, lower discriminative power. The disadvantage of this can be the increasing overfitting risk when the number of observations is insufficient. The significant computation time when the number of variables is large.

6. When is a feature considered irrelevant? What can be said to quantify it?
Ans. A feature is considered irrelevant when it is not highly correlated to the target feature as increasing or decreasing its value does not cause a huge change in the model's accuracy. 

7. When is a function considered redundant? What criteria are used to identify features that could be redundant?
Ans. if two features are highly correlated with one another then they are said to be redundant. Correlation heatmap can be used to identify such features.

8. What are the various distance measurements used to determine feature similarity?
Ans. there are various  distance measurements like:
Euclidean distance
Manhattan distance 
Minkowski distance

9. State difference between Euclidean and Manhattan distances?
Ans. euclidean distance uses euclidean formula  root of((x1-x2)^2+(y1-y2)^2). It is the shortest path from point a to b.where the manhattan distance is calculated by |x1 - x2|+|y1-y2|. It is the sum of all the real distances between points a and b.

10. Distinguish between feature transformation and feature selection.
Ans. feature transformation is transforming or changing the data from its current form to a more representable or processable form. While feature selection deals with the selection of the best feature for the final input for the model.

11. Make brief notes on any two of the following:

1.SVD (Standard Variable Diameter Diameter)
2. Collection of features using a hybrid approach
3. The width of the silhouette
4. Receiver operating characteristic curve

Ans.	1.	Singular Value Decomposition (SVD) is a widely used technique to decompose a matrix into several component matrices, exposing many of the useful and interesting properties of the original matrix
2.	 hybrid feature selection method is proposed for classification in small sample size data sets.The filter step is based on instance learning taking advantage of the small sample size of data. A few candidate feature subsets are generated since their number corresponds to the number of instances
3.	silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from âˆ’1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.
4.	The receiver operating characteristic (ROC) curve is frequently used for evaluating the performance of binary classification algorithms. It provides a graphical representation of a classifier's performance, rather than a single value like most other metrics.
 
